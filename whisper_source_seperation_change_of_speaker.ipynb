{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![notebook shield](https://img.shields.io/static/v1?label=&message=Notebook&color=blue&style=for-the-badge&logo=googlecolab&link=https://colab.research.google.com/github/ArthurFDLR/whisper-youtube/blob/main/whisper_youtube.ipynb)](https://colab.research.google.com/github/Majdoddin/nlp/blob/main/whisper_source_seperation_change_of_speaker.ipynb)\n",
        "[![repository shield](https://img.shields.io/static/v1?label=&message=Repository&color=blue&style=for-the-badge&logo=github&link=https://github.com/openai/whisper)](https://github.com/majdoddin/nlp)\n",
        "# Whisper source seperation\n",
        "This is a demonstration, that whisper can seperate overlapping voices, and generate the transcription for ONE of them."
      ],
      "metadata": {
        "id": "J-YkSRlVnYlN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Installing [`yt-dlp`](https://github.com/yt-dlp/yt-dlp) and downloading the [video](https://youtu.be/NSp2fEQ6wyA) from youtube."
      ],
      "metadata": {
        "id": "Ct4adIANpQvX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e286Uh55rje0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "qlWyYFuOrjig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/myDrive\")"
      ],
      "metadata": {
        "id": "eSZWVh4giH2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir /content/myDrive/MyDrive/ai/whisper3\n",
        "%cd /content/myDrive/MyDrive/ai/whisper3"
      ],
      "metadata": {
        "id": "D3RyjA6SjUL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TL7fC4aZdpyH"
      },
      "outputs": [],
      "source": [
        "  !pip install -U yt-dlp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsedMPN-daEX"
      },
      "outputs": [],
      "source": [
        "  !wget -O - -q  https://github.com/yt-dlp/FFmpeg-Builds/releases/download/latest/ffmpeg-master-latest-linux64-gpl.tar.xz | xz -qdc| tar -x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VHzpv72dkvV"
      },
      "outputs": [],
      "source": [
        "video_url = 'https://youtu.be/NSp2fEQ6wyA'\n",
        "!yt-dlp -xv --ffmpeg-location ffmpeg-master-latest-linux64-gpl/bin --audio-format wav  -o \"audio.wav\" -- {video_url}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "4-xR_GorzL29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "spacermilli = 1000\n",
        "spacer = AudioSegment.silent(duration=spacermilli)\n",
        "\n",
        "audio = AudioSegment.from_wav(\"audio.wav\") \n",
        "sound1 = audio[(4*60+6)*1000+53:]\n",
        "sound1.export('sound1.wav', format='wav')\n",
        "\n",
        "sound2 = audio[(3*60+42)*1000+65:(3*60+50)*1000+750]\n",
        "sound2 = spacer.append(sound2, crossfade=0)\n",
        "sound2.export('sound2.wav', format='wav')\n",
        "\n",
        "combined = sound1.overlay(sound2)\n",
        "combined.export('combined.wav', format='wav')"
      ],
      "metadata": {
        "id": "D15Mp12fzasF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import display, Audio \n",
        "display(Audio('sound1.wav'))\n",
        "display(Audio('sound2.wav'))\n",
        "display(Audio('combined.wav'))"
      ],
      "metadata": {
        "id": "21APLXwJgBJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSzLKZ7vgx9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zou3_iWcgHe7"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper combined.wav --language en --model large"
      ],
      "metadata": {
        "id": "eh1YhO1cgRCz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}